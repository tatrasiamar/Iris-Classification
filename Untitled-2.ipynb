import sklearn
import numpy
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
%pip install scikit-learn==1.3.0
#Load the csv data
import pandas as pd
df=pd.read_csv('IRIS.csv')
df.head()
#describe basic status of data
df.describe()
df.info()
#display no. of samples on each class
df['species'].value_counts()
#check null values
df.isnull().sum()
df['sepal_length'].hist()
df['sepal_width'].hist()
df['petal_length'].hist()
df['petal_width'].hist()
#create list of colors and class labels
colors = ['red','orange']
species=['virginica','setosa']
import seaborn as sns
sns.scatterplot(data=df,x="sepal_length",y="sepal_width",hue="species");
plt.xlabel("Sepal length")
plt.ylabel("Sepal width")
sns.scatterplot(data=df,x="petal_length",y="petal_width",hue="species");
plt.xlabel("Petal length")
plt.ylabel("Petal width")
sns.scatterplot(data=df,x="sepal_width",y="petal_width",hue="species");
plt.xlabel("Sepal Width")
plt.ylabel("Petal Width")
#dispaly the correlation matrix
df.corr()
corr = df.corr()
#plot the heat map
fig, ax=plt.subplots(figsize=(5,4))
sns.heatmap(corr,annot=True,ax=ax,cmap='coolwarm')
#from sklearn.preprocessing import LabelEncoder
#le=LabelEncoder()
#transform the string labels to integer
#dfd['species']=le.fit_transform(df['species'])
#df.head()
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import pickle
#input data
X=df.drop(columns=['species'])
#output data
Y=df['species']
#split the data for train and test
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.30)
#Logistic Regression
model=LogisticRegression()
model.fit(x_train,y_train)
print("Logistic Regression Accuracy:",model.score(x_test,y_test)*100)
#model training
model.fit(x_train.values,y_train.values)
#print metric to get performance
print("Accuracy:",model.score(x_test,y_test)*100)
#K-nearest neighbors
model=KNeighborsClassifier()
model.fit(x_train.values,y_train.values)
print("K-nearest neighbors Accuracy:",model.score(x_test,y_test)*100)
model.fit(x_train.values,y_train.values)
#print metric to get performance
print("Accuracy:",model.score(x_test,y_test)*100)
#Decision Tree
model=DecisionTreeClassifier()
model.fit(x_train.values,y_train.values)
print("Decision Tree Accuracy:",model.score(x_test,y_test)*100)
model.fit(x_train.values,y_train.values)
#print metric to get performance
print("Accuracy:",model.score(x_test,y_test)*100)
#save the model
import pickle
filename='saved_model.sav'
pickle.dump(model,open(filename,'wb'))
import pickle
#save the updated model
filename = 'saved_model.sav'
try:
  with open(filename,'wb') as file:
    pickle.dump(model,file)
  print("Model saved successfully.")
except Exception as e:
  print(f"Error saving the model:{e}")
load_model=pickle.load(open(filename,'rb'))
load_model.predict([[6.0,2.2,4.0,1.0]])
import sklearn
print(sklearn.__version__)
x_test.head()
load_model.predict([[4,3,1,5]])
